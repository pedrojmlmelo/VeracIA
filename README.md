# VeracIA: Verificador de Fake News com Google Gemini
<h1 align="center">
  <br>
  <img src="https://github.com/pedrojmlmelo/VeracIA/blob/main/veracIA.png" alt="Image" height="200" width="200">
  <br>
  <br><br>
</h1>

<p align="center"><i>"O progresso da humanidade se apoia na busca incessante pela verdade."</i> </p>


[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pedrojmlmelo/VeracIA/blob/main/Verificador_de_Fake_News.ipynb)

Este projeto, desenvolvido como parte da Imers√£o Intelig√™ncia Artificial da Alura e do Google, utiliza o poder do modelo de linguagem Google Gemini para auxiliar na verifica√ß√£o de not√≠cias e identificar potenciais fake news atrav√©s de uma arquitetura multi-agente.

## üîé Vis√£o Geral

O VeracIA implementa um sistema com quatro agentes de IA distintos que trabalham em conjunto para analisar a credibilidade de uma not√≠cia fornecida atrav√©s de sua URL:

1.  **Agente Verificador de Fonte:** Avalia a confiabilidade do site da not√≠cia.
2.  **Agente Analisador de Conte√∫do:** Busca por sinais de desinforma√ß√£o e manipula√ß√£o no texto.
3.  **Agente de Checagem Cruzada:** Tenta verificar a veracidade das alega√ß√µes da not√≠cia.
4.  **Agente Sintetizador:** Consolida as an√°lises dos outros agentes para fornecer um parecer final sobre a probabilidade de ser fake news.

## ‚öôÔ∏è Como Funciona

O script em Python utiliza as bibliotecas `google-genai` para interagir com o modelo Gemini e `google-adk` para a cria√ß√£o e gerenciamento dos agentes. O fluxo de opera√ß√£o √© o seguinte:

1.  O usu√°rio √© solicitado a inserir a URL da not√≠cia a ser verificada.
2.  A fun√ß√£o `agente_verificador_fonte` √© chamada para analisar a credibilidade da fonte com base na URL.
3.  O resultado da an√°lise da fonte √© passado para a fun√ß√£o `agente_analisador_conteudo`, que examina o texto em busca de t√©cnicas de desinforma√ß√£o.
4.  A an√°lise do conte√∫do √© ent√£o utilizada pela fun√ß√£o `agente_checagem_cruzada` para verificar as alega√ß√µes presentes na not√≠cia.
5.  Finalmente, a fun√ß√£o `agente_sintetizador` recebe o resultado da checagem cruzada e gera um parecer final, indicando o n√≠vel de probabilidade da not√≠cia ser fake news e fornecendo uma breve justificativa.
6.  O parecer final √© exibido ao usu√°rio no formato Markdown.

## Pr√©-requisitos

Para executar este projeto, voc√™ precisar√° de:

* Uma conta Google Cloud com acesso √† API Gemini.
* Uma chave de API do Google Gemini configurada como um segredo no Google Colab (acess√≠vel via `userdata.get('GOOGLE_API_KEY')`).
* As seguintes bibliotecas Python instaladas:
    ```bash
    %pip install google-genai
    %pip install google-adk
    ```

## Utiliza√ß√£o

Voc√™ pode executar este projeto diretamente no Google Colab atrav√©s do link no topo deste README. Siga estas etapas:

1.  Execute as c√©lulas para instalar as bibliotecas necess√°rias (`google-genai` e `google-adk`).
2.  Certifique-se de ter configurado sua chave de API do Google Gemini como um segredo no Colab com o nome `GOOGLE_API_KEY`.
3.  Execute as c√©lulas que definem as fun√ß√µes auxiliares (`call_agent` e `to_markdown`) e as fun√ß√µes de cada agente (`agente_verificador_fonte`, `agente_analisador_conteudo`, `agente_checagem_cruzada`, `agente_sintetizador`).
4.  Na √∫ltima c√©lula, quando solicitado pela entrada `Por favor, digite a url da noticia:`, cole a URL da not√≠cia que voc√™ deseja verificar e pressione Enter.
5.  O resultado da an√°lise, incluindo o parecer final do `agente_sintetizador`, ser√° exibido logo abaixo da c√©lula de entrada.

## Estrutura do C√≥digo

O c√≥digo principal √© composto por fun√ß√µes que definem a l√≥gica de cada agente e fun√ß√µes auxiliares:

* `call_agent(agent: Agent, message_text: str) -> str`: Fun√ß√£o auxiliar para enviar mensagens aos agentes e obter suas respostas.
* `to_markdown(text)`: Fun√ß√£o auxiliar para formatar o texto de sa√≠da em Markdown para melhor visualiza√ß√£o no Colab.
* `agente_verificador_fonte(url)`: Implementa a l√≥gica do agente para verificar a credibilidade da fonte.
* `agente_analisador_conteudo(fonte_verificada)`: Implementa a l√≥gica do agente para analisar o conte√∫do da not√≠cia.
* `agente_checagem_cruzada(conteudo_analisado)`: Implementa a l√≥gica do agente para realizar a checagem de fatos.
* `agente_sintetizador(cruzada_analisado)`: Implementa a l√≥gica do agente para consolidar as an√°lises e gerar o parecer final.

## Exemplo de Sa√≠da

Ao fornecer a URL `https://medicospelavida.org.br/noticias/a-145a-live-comunica-mpv-de-terca-feira-15-as-20h30-vai-trazer-informacoes-importantes-sobre-audiencias-publicas-a-respeito-da-inoculacao-obrigatoria-de-criancas/`, o sistema gerou a seguinte an√°lise (o resultado pode variar ligeiramente):

> Com base na an√°lise apresentada, o site medicospelavida.org.br apresenta alta probabilidade de disseminar fake news. A reputa√ß√£o question√°vel, a falta de base em evid√™ncias cient√≠ficas, alega√ß√µes n√£o comprovadas sobre vacinas (como miocardite e pericardite) e tratamentos como a ivermectina, o questionamento da efic√°cia das vacinas e a promo√ß√£o de tratamentos sem comprova√ß√£o como a hidroxicloroquina s√£o indicativos fortes de desinforma√ß√£o. Al√©m disso, as cr√≠ticas √† cobertura da m√≠dia podem ser uma t√°tica para promover narrativas alternativas.
>
> **Nota:** Alta probabilidade de ser fake news.

## Contribui√ß√£o

Este projeto foi desenvolvido para fins educacionais durante a Imers√£o IA da Alura e do Google. Contribui√ß√µes para melhorias ou novas funcionalidades s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.

## Agradecimentos

Gostaria de agradecer √† Alura e ao Google por proporcionarem a Imers√£o em Intelig√™ncia Artificial e a oportunidade de desenvolver este projeto.
